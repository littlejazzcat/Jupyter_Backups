### 《动手学深度学习》第一章

- 使用到的库：<code>import torch</code>

- 使用到的方法：

```python

'''
这里的生成的数据类型都是tensor类型
dim = 0 表示0轴，即行；dim = 1 表示1轴，即列
'''

torch.arange(num) #创建一个行向量或者单轴张量，共num列，

torch.arange(i:j) #创建一个i行j列的张量

x.shape  #访问张量的形状 结果例子：torch.Size([6, 4])

x.numel()  #返回张量的大小（行数乘以列数）

y = x.reshape(i,j) #将x张量转换成i行j列的张量，当其中一个参数为
                   #-1时则会自动计算该轴对应的值，例如原张量size为
                   #12时，x.reshape(-1,3)则会生成一个4行3列的张量

#全0张量
torch.zeros(2,3,4) 

'''
---->tensor([[[0., 0., 0., 0.],
              [0., 0., 0., 0.],
              [0., 0., 0., 0.]],

             [[0., 0., 0., 0.],
             [0., 0., 0., 0.],
             [0., 0., 0., 0.]]])
'''
torch.zeros_like(y) #和y张量形状一样的全0张量

#全1张量
torch.ones(2,3,4)
'''
---->tensor([[[1., 1., 1., 1.],
              [1., 1., 1., 1.],
              [1., 1., 1., 1.]],

             [[1., 1., 1., 1.],
              [1., 1., 1., 1.],
              [1., 1., 1., 1.]]])
'''

#均值为0，标准差为1的正态分布随机采样
torch.randn(3,4)

#直接赋值
torch.tensor([[2, 1, 4, 3], [1, 2, 3, 4], [4, 3, 2, 1]])

#基本运算符
x = torch.tensor([1.0, 2, 4, 8])
y = torch.tensor([2, 2, 2, 2])
x + y, x - y, x * y, x / y, x ** y  # **运算符是求幂运算
#都是线代里的矩阵的点运算（点乘、点除等）

#e的x次幂
torch.exp(x)

#张量粘贴(cat)，dim = 0,y按行粘贴到x；dim = 1,y按列粘贴到x上
torch.cat((X, Y), dim=0), torch.cat((X, Y), dim=1)

#逻辑相等,判断的是张量中每个元素是否相等
x == y
'''
ans
tensor([[False,  True, False,  True],
        [False, False, False, False],
        [False, False, False, False]])
'''

#求和，对张量中所有元素求和，结果也是tensor类型
x.sum() #例ans ：tensor(66.)

#张量广播机制

###########！！！！！！！！！！！
#这里要注意python的可变对象的内存分配机制
Y = X + Y 
'''这样会给Y重新分配新的内存，而在机器学习中，我们可能有数百兆的参数，
并且在一秒内多次更新所有参数。通常情况下，我们希望原地执行这些更新；如果我们不
原地更新，其他引用仍然会指向旧的内存位置，这样我们的某些代码可能会无意中引用旧
的参数。'''

#处理方法：
#可以使用X[:] = X + Y或X += Y来减少操作的内存开销。

#大小为1的张量转换为python标量：
a = torch.tensor([3.5])
a, a.item(), float(a), int(a)
#ans：(tensor([3.5000]), 3.5, 3.5, 3)

```